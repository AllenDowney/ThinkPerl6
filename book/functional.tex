\chapter{Functional Programming}
\label{functional programming}
\index{functional programming}

Functional programming is a programming paradigm that treats 
computation as the evaluation of mathematical functions 
and avoids changing-state and mutable data. It is a 
declarative programming paradigm, which means programming 
is done with expressions or declarations instead of 
statements. In functional code, the output value of a function 
depends only on the arguments that are input to the function, 
so calling a function twice with the argument will produce the 
same result each time. Eliminating side effects, i.e. changes 
in state that do not depend on the function inputs, can make 
it much easier to understand and predict the behavior of a 
program, which is one of the key motivations for the 
development of functional programming.

Perl is not a functional language in the sense that it is 
also using many other programming paradigms that we have been 
using abundantly throughout this book. It does however 
offer extensive functional programming features and 
capabilities, some of which have been introduced in 
various sections of this book and will be briefly 
reviewed here before we get further.

\section{Higher order functions}
\index{higher-order functions}

As early as chapter~\ref{funcchap} on functions and 
subroutines, in Section~\ref{first_class} 
(p.~\pageref{first_class}), we have seen that functions,  
subroutines and other code objects are \emph{first-class 
objects} or \emph{first-class citizens} in Perl, which 
means that they can be passed around as values. A Perl~6 
function is a value you can assign to a variable or pass 
around as an argument or a return value from another 
function.
\index{first-class object}
\index{object, first-class}
\index{first-class citizen}
\index{citizen, first-class}

\subsection{A refresher on functions as first-class objects}
\label{fco-refresher}

Our initial very simple example was something 
like this:

\begin{verbatim}
sub do-twice(&code) {
    &code(); 
    &code();
}
sub greet {
    say "Hello World!";
}
do-twice &greet;
\end{verbatim}

in which the {\tt greet} subroutine was passed as an 
argument to the {\tt do-twice} subroutine, with the 
effect of printing twice the greeting message. A 
function that is passed as an argument to another function 
is often called a \emph{callback function}.
\index{callback function}

The \verb"&" sigil placed before the {\tt greet} 
subroutine name in the argument list as well as before 
the {\tt code} parameter in the signature and in the 
body of the {\tt do-twice} subroutine tells Perl 
that you are passing around a subroutine or some 
other callable code object.
% TODO: get these entries working in plastex
\ifplastex \else
\index{\& sigil@\texttt{\&} sigil}
\fi

In computer science, a subroutine that can take 
another subroutine as an argument is sometimes 
called a \emph{higher-order function}.
\index{higher-order function}
\index{function!higher-order}

More interesting examples of higher-order function 
are found with the {\tt reduce}, {\tt map}, and
{\tt grep} functions studied in section~\ref{map_filter} 
(p.~\pageref{map_filter}), as well as the {\tt sort} 
function (sections~\ref{sorting} and \ref{advanced_sort}).

Let's consider for example the task of sorting by date 
records consisting in an identifier followed by a date 
in the DD-MM-YYYY format, such as ``id1;13-05-2015'' 
or ``id2;17-04-2015''. The records need quite a bit of 
transformation before we can compare them for the sake 
of finding the chronological order in which they should 
be sorted, so we might write separate a comparison 
function:
\index{sort}

\begin{verbatim}
sub compare ($rec1, $rec2) {
    my $cmp1 = join ",", reverse split /<[;-]>/, $rec1;
    my $cmp2 = join ",", reverse split /<[;-]>/, $rec2;
    return $cmp1 cmp $cmp2;
}   
\end{verbatim}

Each modified record is constructed by chaining three 
functions. These lines should be read from right to left: 
first, the input value is split into four items, these 
items are then reversed and then joined, so that the result 
for ``id1;13-05-2015'' is ``2015,05,13,id1'', which is 
adapted for a comparison with the {\tt cmp} function. We 
will come back soon to this form of pipeline programming 
and others ways of performing these operations. 
\index{cmp function}
\index{pipeline programming}

We can now pass the {\tt compare} subroutine to the 
{\tt sort} function:
\begin{verbatim}
.say for sort &compare, <id1;13-05-2015 id2;17-04-2015 
                         id3;21-02-2016 id4;12-01-2015>;
\end{verbatim}

which displays:
\begin{verbatim}
id4;12-01-2015
id2;17-04-2015
id1;13-05-2015
id3;21-02-2016
\end{verbatim}

Please note that this is provided as an example of callback 
functions used with the {\tt sort} built-in function. We will 
see at the end of the next subsection a simpler way to accomplish 
the same type of sort using an anonymous subroutine. 

\subsection{Anonymous subroutines and lambdas}
\index{lambda}
\index{anonymous subroutine}

We have also seen that a subroutine does not need to 
have a name and can be \emph{anonymous}. For example, 
it may be stored directly into a scalar variable:
\index{anonymous function}
\index{function!anonymous}

\begin{verbatim}
my $greet = sub {
    say "Hello World!";
};
do-twice $greet;                 # prints "Hello World" twice
\end{verbatim}

We don't even need to store the code of the anonymous function 
in the \verb'$greet' variable; we can pass it directly as an 
argument to the {\tt do-twice} subroutine:

\begin{verbatim}
do-twice(sub {say "Hello World!"} );
\end{verbatim}

Since the anonymous subroutine does not take any argument 
and does not return a useful value, we can simplify the 
syntax further and pass a simple anonymous code block 
to {\tt do-twice}:

\begin{verbatim}
do-twice {say "Hello World!"};   # prints "Hello World" twice
\end{verbatim}

More useful examples of anonymous subroutines have been 
seen (see section~\ref{map_filter} for explanations or 
details):
\begin{itemize}
\item With the {\tt reduce} function to compute the sum of 
the first 20 integers:
\index{reduce function}
\begin{verbatim}
my $sum = reduce { $^a + $^b }, 1..20; # -> 210
\end{verbatim}
\item With the {\tt map} function to capitalize the first 
letter of a list of cities (using the {\tt tc} built-in):
\index{tc function}
\index{map function}
\begin{verbatim}
> .say for map {.tc}, <london paris rome washington madrid>;
London
Paris
Rome
Washington
Madrid
\end{verbatim}
\item with the {\tt grep} function to generate a list of even 
numbers by filtering out odd numbers:
\index{grep function}
\begin{verbatim}
my @evens = grep { $_ %% 2 }, 1..17; # -> [2 4 6 8 10 12 14 16]
\end{verbatim}
\end{itemize} 

The example with {\tt reduce} is of special interest. In 
principle, contrary to a subroutine, you cannot easily pass 
arguments to a code block (because it has no signature). 
But the use of the self-declared positional parameters 
(or placeholders) with the \verb'$^' twigil makes it 
possible to use parameters within the block. 
\index{placeholder}
\index{placeholder parameter}
\index{twigil}
\index{self-declared parameter}

Because of this possibility, the anonymous code block becomes 
what is commonly called a \emph{lambda} in computer science (and 
in mathematics), i.e. a kind of nameless function. Lambda 
calculus, a mathematical theory invented in the 1930s by 
Alonzo Church, is the root of most of today's functional 
programming languages.
\index{lambda}
\index{lambda calculus}
\index{Church, Alonzo}

Actually, the two other examples above using the \verb'$_' 
topical variable are also lambdas. Although we haven't 
mentioned it, some other constructs we have seen earlier are 
also lambdas. In particular, the ``pointy block'' syntax 
used twice in the following {\tt for} loops displaying 
the multiplication tables:
\index{pointy block}
\index{for loop}
\index{multiplication tables}

\begin{verbatim}
for 1..9 -> $mult {
    say "Multiplication table for $mult";
    for 1..9 -> $val {
        say "$mult * $val = ", $mult * $val;
    }
}
\end{verbatim}

is another form of lambda where the ``function'' parameter is 
defined by the pointy block loop variable.

The sorting example presented in the previous subsection 
(\ref{fco-refresher}) may also be rewritten with an 
anonymous code block (taking advantage of the {\tt sort} 
syntax using a code block with a single argument described 
in section~\ref{advanced_sort}):
\index{sort}
\begin{verbatim}
my @in = <id1;13-05-2015 id2;17-04-2015 id3;21-02-2016>;
.say for sort { join ",", reverse split /<[;-]>/, $_ }, @in;
\end{verbatim}

Here again, the somewhat long code block passed as an 
argument to the {\tt sort} function is a lambda.
\index{lambda}

\subsection{Closures}
\index{closure}

In computer programming, a \emph{closure} (or \emph{lexical 
closure}) is a function which can access to variables that 
are lexically available where the function is defined, even 
if those variables are no longer in scope in the code section 
where the function is called.
\index{counter}

Consider the following example:

\begin{verbatim}
sub create-counter(Int $count) {
    my $counter = $count;
    sub increment-count {
        return $counter++
    }
    return &increment-count;
}
my &count-from-five = create-counter(5);
say &count-from-five() for 1..6; # prints numbers 5 to 10
\end{verbatim}

The {\tt create-counter} subroutine initializes the 
\verb'$counter' variable to the value of the received 
parameter, defines the {\tt increment-count} subroutine 
and returns this subroutine. The main code calls 
{\tt create-counter} to create dynamically the 
\verb'&count-from-five' code reference (and could 
call it many times to create other counters counting 
from 6, 7, and so on).  Then, \verb'&count-from-five' 
is called six times and prints out numbers between 5 
and 10, each on its own line.
\index{lexical scope}
\index{scope!lexical}

The magical thing here is that the \verb'$counter' variable 
is out of scope when \verb'&count-from-five' is called, 
but \verb'&count-from-five' can access it, return its value, 
and increment it because \verb'$counter' was within the 
lexical scope at the time the {\tt increment-count} was 
defined. It is commonly said that {\tt increment-count} 
``closes over'' the \verb'$counter' variable. 
The {\tt increment-count} subroutine is a closure.

The above example is a bit contrived and its syntax 
somewhat awkward because we wanted to show an example 
of a named closure ({\tt increment-count} is a named 
subroutine). It is usually simpler and more idiomatic 
to use anonymous closures and to rewrite the example 
as follows:
\index{idiomatic}

\begin{verbatim}
sub create-counter(Int $count) {
    my $counter = $count;
    return sub {
        return $counter++
    }
}
my &count-from-five = create-counter(5);
say &count-from-five() for 1..6; # prints numbers 5 to 10
\end{verbatim}

You could even simplify {\tt create-counter} further 
with implicit {\tt return} statements:

\begin{verbatim}
sub create-counter(Int $count) {
    my $counter = $count;
    sub { $counter++ }
}
\end{verbatim}

but this is arguably less clear because the code intent 
is less explicit.

The last {\tt create-fifo} example in the solution to 
the FIFO queue exercise (subsection~\ref{functional_queue}) 
is another example of the same mechanism:

\begin{verbatim}
sub create-fifo {
    my @queue;
    return (
        sub {return shift @queue;}, 
        sub ($item) {push @queue, $item;}
        ) ;
}
my ($fifo-get, $fifo-put) = create-fifo();
$fifo-put($_) for 1..10;
print " ", $fifo-get() for 1..5; # ->  1 2 3 4 5
\end{verbatim}
%
\index{closure}
\index{FIFO}
\index{anonymous subroutine}

In Perl~6, all subroutines are closures, which means that 
all subroutines can access to lexical variable that 
existed in the environment at the time of their definition, 
but they don't necessarily act as closures.

In fact, all code objects, even simple anonymous code 
blocks, can act as closures, which means that they can 
reference lexical variables from the outer scope, and this 
is in effect what is going on with the loop variable of 
a pointy block or in the following {\tt map} block:

\begin{verbatim}
my $multiplier = 7;
say  map {$multiplier * $_}, 3..6; # -> (21 28 35 42)
\end{verbatim}

Here the block passed to map references the variable 
\verb'$multiplier' from the outer scope, making the 
block a closure.

Languages without closures cannot easily provide 
higher-order functions that are as easy to use and 
powerful as {\tt map}.
\index{map}
\index{function!map}

This is just another example of a block acting as a 
closure for a counter implementation:

\begin{verbatim}
my &count;
{
    my $counter = 10;
    &count = { say $counter++ };
}
&count() for 1..5;  
\end{verbatim}

This closure saves a reference to the \verb'$counter' 
variable when the closure is created. The call to the 
\verb'&count' code block successfully displays and 
updates \verb'$counter', even if that variable is no
longer in lexical scope when the block is executed.
\index{scope!lexical}
\index{lexical scope}
\index{closure}

\section{List processing and pipe-line programming}
\index{pipe-line programming}

Quite often, a computation can be expressed as a 
series of successive transformations on a list of 
values. Perl provides functions able to work on 
the items of a list and apply simple actions, 
callback functions or code blocks to these items. 
Among those, we have already seen and used abundantly 
the following:
\begin{enumerate}
\item {\tt map} applies a transformation of each item 
of a list;
\index{map} \index{function!map}
\item {\tt grep} is a filter that keeps only the items 
for which the function or code block associated with 
{\tt grep} evaluates to true;
\index{grep} \index{function!grep}
\item {\tt reduce} uses each item of a list to compute 
a single scalar value;
\index{reduce} \index{function!reduce}
\item {\tt sort} sorts the elements of a list in accordance 
to the rules defined in the passed code-block or 
subroutine. 
\index{sort} \index{function!sort}
\end{enumerate}

We have seen several examples where these functions can 
be used together in a sort of data pipe-line in which 
the data produced by each step of the pipe-line is fed 
to the next step. For example, in the preceding section 
(subsection~\ref{fco-refresher}), we've used this:

\begin{verbatim}
    my $cmp1 = join ",", reverse split /<[;-]>/, $rec1;
\end{verbatim}
\index{reverse} \index{function!reverse}
\index{split} \index{function!split}
\index{join} \index{function!join}

As we said, this type of code should be read from right 
to left (and from bottom to top if written over several 
code lines): \verb'$rec1' is fed to {\tt split}, which 
splits the data item into four pieces; the pieces are then 
reversed and then fed to {\tt join} to reconstruct a single 
data item when the pieces are now in reversed order.

Similarly, we could produce a list of children of single 
mothers with the following code chaining several methods:

\begin{verbatim}
my @children-of-single-moms =
    map  {  .children },
    grep { !.is-married },
    grep {  .gender eq FEMALE },
         @citizens;
\end{verbatim}
\index{map} \index{function!map}
\index{grep} \index{function!grep}

This one should be read bottom to top. It takes a list 
of all citizens, filters those who are female, filters 
those who are not married, and list the children of 
such unmarried women. Note that {\tt .children} may 
return one child, a list of several children or an 
empty list. {\tt map} has a flattening influence 
on the lists thus produced, so the final result is 
a flat list of children.

These pipelines are very powerful and expressive, and 
can get a lot done in a few code lines.

\subsection{Feed and backward feed operators}

Although it is easy to get used to it, it may be 
considered inconvenient that the steps are laid 
out in reverse order of processing in the previous 
examples.

Perl~6 provides the \verb'==>' \emph{feed} operator 
(sometimes called \emph{pipe} in other languages) 
that makes it possible to write the various pipeline 
steps in a ``more natural'', left to right, order.
\index{feed operator}
\index{operator!feed}
% TODO: get these entries working in plastex
\ifplastex \else
\index{==> feed operator@\texttt{==>} feed operator}
\fi

For example, reusing the example of sorting records 
by dates seen earlier in this chapter:
\index{sort}

\begin{verbatim}
"id1;13-05-2015" 
    ==> split(/<[;-]>/) 
    ==> reverse() 
    ==> join(",") 
    ==> my @out;  # @out is now: [2015,05,13,id1]
\end{verbatim}

By the way, if you're using such pipeline operations on 
a large input, and depending on your platform 
architecture, Perl~6 may be able to run these 
various operations in parallel on different CPU's or cores, 
thereby improving significantly the performance 
of the overall process.

There is also a backward feed operator, \verb'<==', 
enabling to write the pipeline in reverse order:
\index{backward feed operator}
\index{operator!backward feed}
% TODO: get these entries working in plastex
\ifplastex \else
\index{<== backward feed operator@\texttt{<==} backward feed operator}
\fi

\begin{verbatim}
my $out <== join(",") 
        <== reverse() 
        <== split(/<[;-]>/) 
        <== "id1;13-05-2015";
\end{verbatim}


\subsection{The reduction metaoperator}

We have already met this meta-operator in section~\ref{map_filter}. 
A meta-operator acts on other operators. Given 
a list and an operator, the [...] reduction meta-operator 
applies repeatedly the operator to all the values of the
list to produce a single value.
\index{metaoperator}
\index{reduction}
\index{reduction!metaoperator}

For example, the following prints the sum of all the 
elements of a list:

\begin{verbatim}
say [+] 1..10;      # -> 55
\end{verbatim}

Similarly, we can write a factorial function as:
\index{factorial!using the reduction meta-operator}

\begin{verbatim}
sub fact (Int $n where $n >= 0) {
    return [*] 1..$n;
}
say fact 20;        # -> 2432902008176640000
say fact 0;         # -> 1
\end{verbatim}

(Note that this yields the correct result even for the 
edge case of factorial 0, which is defined mathematically 
to be 1.)

\subsection{The hyperoperator}

\index{hyperoperator}
An hyperoperator applies the specified operator to each 
item of a list (or two lists in parallel) and return a 
modified list (somewhat similarly to the {\tt map} 
function). It uses the so-called French or German 
quote marks, \verb'« »' (Unicode codepoints U+00AB 
and U+00BB), but you can use their ASCII equivalent 
double angle brackets, \verb'<< >>', if you prefer 
(or don't know how to enter those Unicode characters 
with your editor).
\index{French quote marks}
\index{German quote marks}

Our first example will multiply each element of a list 
by a given number (5):

\begin{verbatim}
my @b = 6..10;
my @c = 5 «*» @b;
say @c;             # prints 30 35 ... 50 (5*6, 5*7, ...)
\end{verbatim}

We can also combine two lists and, for example, add 
respective values:

\begin{verbatim}
my @a = 1..5;
my @b = 6..10;
my @d = @a >>+<< @b;
say @d;             # -> [7 9 11 13 15]
\end{verbatim}

You can also use hyperoperators with a unary operator:

\begin{verbatim}
my @a = 2, 4, 6;
say -« @a;          # prints:  -2 -4 -6
\end{verbatim}

Hyperoperators with unary operators always return a 
list having the same size as the input list. Infixed 
hyperoperators have a different behavior depending on 
the size of their operands:

\begin{verbatim}
@a >>+<< @b;   # @a and @b must have the same size
@a <<+<< @b;   # @a can be smaller
@a >>+>> @b;   # @b can be smaller
@a <<+>> @b;   # Either can be smaller, Perl will do 
               # probably what you mean (DWIM principle)
\end{verbatim}

Hyperoperators also work with modified assignment 
operators:

\begin{verbatim}
@x >>+=<< @y   # Same as: @x = @x >>+<< @y
\end{verbatim}
\index{hyperoperator}

\subsection{The ``X'' cross and ``Z'' zip operators}
\index{cross operator X}
\index{operator!cross}
\index{operator!X (cross)}
\index{zip operator Z}
\index{operator!zip}
\index{operator!Z (zip)}

The cross operator uses the capital letter ``\verb"X"''.
It takes two or more lists as arguments and returns a list 
of all lists that can be constructed combining the elements 
of each list (a form of ``Cartesian product''):
\index{cross operator}
\index{operator!cross}
\index{X cross operator}

\begin{verbatim}
my @a = 1, 2;
my @b = 3, 4;
my @c = @a X @b;       # -> [(1,3), (1,4), (2,3), (2,4)]
\end{verbatim}

The cross operator may also be used as a metaoperator and 
apply the operator that it modifies to each item combination 
derived from its operands:
\index{metaoperator}

\begin{verbatim}
my @a = 3, 4;
my @b = 6, 8;
say @a X* @b;    # -> 18 24 24 32
\end{verbatim}

If no additional operator is supplied (as in the first 
example above), ``\verb"X"'' acts as if a comma is 
provided as default additional operator. 

The ``\verb"Z"'' zip operator interleaves the lists 
like a zipper:
\index{zip operator}
\index{operator!zip}
\index{Z zip operator}

\begin{verbatim}
say 1, 2 Z <a b c > Z 9, 8;   # -> ((1 a 9) (2 b 8))
\end{verbatim}

The \verb'Z' operator also exists as a metaoperator, in 
which case the inner lists are replaced by the value 
from applying the operator to the list:
\index{metaoperator}

\begin{verbatim}
say 1, 2, 3 Z~ <a b c > Z~ 9, 8, 7; # -> (1a9 2b8 3c7)
\end{verbatim}

\subsection{List operators, a summary}

The list operators we have seen above are powerful 
and can be combined together to produce incredibly 
expressive constructs.

As an exercise, try to solve the following small 
quizzes (please don't read on until you have tried 
to do it and try to do it with the operators we've 
just seen):

\begin{itemize}
\item Given that the {\tt lcm} built-in function 
returns the least common multiple of two numbers, 
write a program which displays the smallest positive 
number divisible by all numbers between 1 and 20.
\index{lcm function}

\item Write a program that computes the sum of all 
digits of factorial 100.

\item Find the difference between the square of the sum 
of the 100 first integers and the sum of the squares of 
the 100 first integers.
\end{itemize}

Please, again, don't read further until you have tried 
(and hopefully succeeded) to solve these quizzes.

The reduction operator makes it possible to apply an 
operator to all elements of a list. Thus, using it 
with the {\tt lcm} function gives the LCM of numbers 
between 1 and 20:
\index{reduction metaoperator}

\begin{verbatim}
say [lcm] 1..20;                 # -> 232792560
\end{verbatim}

For the sum of the digits of factorial 100, we use 
twice the \verb'[]' reduction metaoperator, once with 
the multiplication operator to compute factorial 100, 
and another time with the addition operator to sum 
the digits of the result:
\index{reduction metaoperator}

\begin{verbatim}
say [+] split '', [*] 2..100;    # -> 648
\end{verbatim}

For the square of the sum minus the sum of the squares, 
it is easy to compute the sum of the 100 first integers 
with the reduction operator. The \verb'<<...>>' 
hyperoperator easily supplies a list of the squares of 
these integers, and another application of the reduction 
operator reduces this list to a sum:
\index{hyperoperator}

\begin{verbatim}
say ([+] 1..100)**2 - [+] (1..100) «**» 2; # -> 25164150
\end{verbatim}

\subsection{Creating new operators}

We have briefly seen (section~\ref{operator_construction}) 
that you can build new operators or redefine existing ones 
for new types.

The example we gave was to define the ``-'' minus sign 
as an infix operator between two hashes in order to 
perform a kind of mathematical set subtraction, i.e. 
to find all keys of the first hash that are not in the 
second hash.
\index{operator type!infix}

\index{operator type!prefix}
In the previous paragraph, the word \emph{infix} means 
that this is a binary operator (two operands) that will 
be placed between the two operands. 

There are other flavors of operators:
\begin{itemize}
\item Prefix: a unary operator placed before the operand, 
for example the minus sign in the expression $-1$;
\index{operator type!prefix}

\item Postfix: a unary operator placed after the operand, 
for example the exclamation mark used as a mathematical  
symbol for the factorial: $5!$;
\index{operator type!postfix}

\item Circumfix: an operator made of two symbols placed 
around the operand(s), for example the parentheses $(...)$ 
or the angle brackets $<...>$;
\index{operator type!circumfix}

\item Postcircumfix: an operator made of two symbols placed 
after an operand and around another one, for example the 
square brackets in \verb'@a[1]';
\index{operator type!postcircumfix}
\end{itemize}

To declare a new operator, you usually need to specify 
its type (prefix, postfix, etc.), followed by a colon, 
followed by the operator symbol or name between angle brackets, 
followed by the function signature and body defining 
the operator. For example, we could define a prefix \% 
operator as follows:

\begin{verbatim}
multi sub prefix:<%> (Int $x) {   # double operator
    2 *  $x;
}
say % 21;   # -> 42
\end{verbatim}

This is just an example to show how it works, \% would 
probably not be a good name for a double operator. The 
interesting point, though, is we have re-used an existing 
operator (the modulo operator), but the compiler does not 
get confused because modulo is an infix operator and our 
new operator is defined as a prefix operator.
\index{modulo operator}

A better naming example might be to use ``!'' exclamation 
mark to be a postfix factorial operator, just as in 
mathematical notation:
\index{factorial!operator}

\begin{verbatim}
multi sub postfix:<!> (Int $n where $n >= 0) {
    [*] 2..$n;
}
say 5!;                     # -> 120
\end{verbatim}

Note that the exclamation mark used as a prefix 
operator (i.e. placed before its operand) is 
a negation operator, but there is usually no possible 
confusion between the two operators because one is a 
prefix operator and our new operator is a postfix operator 
(although you might have to be a bit careful on where 
to put whitespace if your expression is somewhat 
complicated). The {\tt multi} keyword isn't strictly 
required here, but it is probably good practice to 
put it anyway, just to cover the cases where it is 
needed. 

As another example, you could define the $\Sigma$ (sum) 
operator as follows:

\begin{verbatim}
multi sub prefix:<Σ> (*@num-list) {
    [+] @num-list;
}
say Σ (10, 20, 12);         # -> 42
\end{verbatim}

The benefit of using the $\Sigma$ operator over using 
directly \verb'[+]' may not be very obvious, but it is 
sometimes very useful to create a ``domain-specific 
language''(DSL), i.e. a sub-language specifically 
adapted for a specific context or subject-matter (e.g., math 
or chemistry), which allows a particular type of problem 
or solution to be expressed more clearly than the 
existing core language would allow. In Perl~6, the 
grammars and the ease to create new operators make 
this creation of DSL quite an easy task.
\index{domain-specific language (DSL)}
\index{DSL (domain-specific language)}


The new operator does not have to be declared between 
angle brackets. The following declarations could 
all be used to define an addition operator:

\begin{verbatim}
infix:<+>
infix:<<+>>
infix:«+»
infix:('+')
infix:("+")
\end{verbatim}

You can also specify the precedence of your new 
operators (relative to existing ones). For example:
\index{precedence}
\index{operator!precedence}

\begin{verbatim}
multi sub infix:<mult> is equiv(&infix:<*>) { ... }
multi sub infix:<plus> is equiv(&infix:<+>) { ... }
mutli sub infix:<zz> is tighter(&infix:<+>) { ... }
mutli sub infix:<yy> is  looser(&infix:<+>) { ... }
\end{verbatim}

In one of his articles (\emph{Structured Programming with 
go to statements}, Dec. 1974), Donald Knuth, a very famous 
computer scientist, uses the \verb':=:' symbol as a 
pseudo-code operator to express the variable interchange 
(or swap) of two values, i.e. the following operation:
\index{Knuth, Donald}
\index{swap}
\index{variable interchange}

\begin{verbatim}
# Caution: this is pseudo-code, not working code, at this point
my $a = 1; my $b = 2;
$a :=: $b; 
say "$a $b";  # -> 2 1 
\end{verbatim}
\index{pseudo-code}

In Knuth's paper, this is just a pseudo-code shortcut 
to discuss more easily Tony Hoare's quicksort algorithm, but 
we can easily implement that symbol:
\index{swap operator}
\index{sort!quicksort}
\index{Hoare, Charles Antony Richard}

\begin{verbatim}
multi sub infix:<:=:> ($a is rw, $b is rw) {
    ($a, $b) = $b, $a;
}
\end{verbatim}

Note that this can also be written this way:

\begin{verbatim}
multi sub infix:<:=:> ($a is rw, $b is rw) {
    ($a, $b) .= reverse; # equivalent to: ($a, $b) = ($a, $b).reverse 
\end{verbatim}

We can now test it for real on the following examples;

\begin{verbatim}
my ($c, $d) = 2, 5;
say $c :=: $d;             # -> (5 2)
# using it to swap two array elements:
my @e = 1, 2, 4, 3, 5;
@e[2] :=: @e[3];
say @e;                    # -> [1 2 3 4 5]
\end{verbatim}

Now, the pseudo-code above now just works fine as real code. 
A sort algorithm such as the one presented below 
(\ref{combsort}) may typically have code lines 
like these to swap two elements of an array:
\index{swap}

\begin{verbatim}
if $some-condition {
    my ($x, $y) = @array[$i], @array[$i + gap];
    @array[$i], @array[$i + gap] = $y, $x;
}
\end{verbatim}

If the above  \verb':=:' operator is defined, we 
could just rewrite these lines as follows:

\begin{verbatim}
@array[$i] :=: @array[$i + gap] if $some-condition;
\end{verbatim}

A final interesting point. Suppose we want to use 
the $\oplus$ operator for the mathematical set 
union between two hashes. This could easily be 
written as follows:
\index{$\oplus$ operator}
\index{operator!$\oplus$}
\index{hash merge operator}

\begin{verbatim}
multi sub infix:<⊕> (%a, %b) {
    my %c = %a;
    %c{$_} = %b{$_} for keys %b;
    return %c
}
\end{verbatim}

This works fine:

\begin{verbatim}
my %q1 = jan => 1, feb => 2, mar => 3;
my %q2 = apr => 4, may => 5, jun => 6;
my %first_half = %q1 ⊕ %q2;
say %first_half;
# {apr => 4, feb => 2, jan => 1, jun => 6, mar => 3, may => 5}
\end{verbatim}

So far, so good, nothing really new. But the new 
infix $\oplus$ operator has now become almost the same 
as a Perl built-in operator, so that we can use it 
together with the reduction metaoperator:
\index{reduction metaoperator}

\begin{verbatim}
my %q1 = jan => 1, feb => 2, mar => 3;
my %q2 = apr => 4, may => 5, jun => 6;
my %q3 = jul => 7, aug => 8, sep => 9;
my %q4 = oct => 10, nov => 11, dec => 12;
my %year = [⊕] %q1, %q2, %q3, %q4;
say %year;
# {apr => 4, aug => 8, dec => 12, feb => 2, jan => 1, 
# jul => 7, jun => 6, mar => 3, may => 5, nov => 11, 
# oct => 10, sep => 9}
\end{verbatim}

Everything works as if this new operator was part 
of the Perl~6 grammar. And that's in effect what 
has happened here: we have really extended the 
language with a new operator. This possibility of 
extending the language is key to the ability of  
Perl~6 to cope with future needs that we can't even 
think of at present time.
\index{extending the language}

\section{Creating your own map-like functions}
\index{map}
 
We have seen in this chapter and in 
section~\ref{map_filter} (p.~\pageref{map_filter}) 
how higher-order functions such as the {\tt reduce}, 
{\tt map}, {\tt grep}, and {\tt sort} functions 
can be powerful and expressive. There are some 
other such built-in functions in Perl, but we would 
like to be able to create our own.

\subsection{Custom versions of map, grep, etc.}

\subsubsection{my-map, a pure Perl version of map}
\index{my-map}

Let's start by trying to rewrite in pure Perl the 
{\tt map} function. It needs to take a subroutine 
or a code block as its first argument, to apply it 
to an array or a list and to return the modified 
list.

\begin{verbatim}
sub my-map (&code, @values) { 
    my @temp;
    push @temp, &code($_) for @values;
    return @temp;
}
my @result = my-map { $_ * 2 }, 1..5; 
say @result;                   # -> [2 4 6 8 10]
\end{verbatim}

This works exactly as expected on the first trial. 
(I made in the past the same experiment with some 
other languages, including Perl~5, it took quite 
a few tries before getting it right, especially 
regarding the calling syntax. Here, everything 
falls into place naturally.) To tell the truth, 
the test is very limited and there may very well be 
some edge cases when {\tt my-map} does not work 
the same way as {\tt map}, but our aim was not to 
clone {\tt map} exactly; the point is that it is 
quite simple to build a higher-order subroutine 
behaving essentially the same way as {\tt map}. 
\index{higher-order subroutine}
\index{map}

\subsubsection{my-grep}
\index{my-grep}
\index{grep}

Writing our version of {\tt grep} is just about as 
easy:
\begin{verbatim}
sub my-grep (&code, @values) { 
    my @temp;
    for @values -> $val {
        push @temp, $val if &code($val);
    }
    return @temp;
}
my @even = my-grep { $_ %% 2 }, 1..10; 
say @even;                   # -> [2 4 6 8 10]
\end{verbatim}

\subsection{Our own version of a sort function}
\label{combsort}
\index{sort!comb sort}

We can similarly write our own version of the sort 
function. 

\index{sort!merge sort}
\index{sort!quicksort}
The Perl {\tt sort} function implements a sort 
algorithm known as \emph{merge sort}.  Some 
previous versions of the Perl language (prior to 
version~5.8) implemented another algorithm known 
as \emph{quick sort}. The main reason for this 
change was that, although quick sort is on average  
a bit faster than merge sort, there are specific 
cases where quick sort is much less efficient than 
merge sort (notably when the data is almost sorted). 
These cases are very rare with random data, but not 
in real situations: it is quite common that you have 
to sort a previously sorted list in which only a 
few elements have been added or modified.

In computing theory, it is frequently said that, for 
sorting \emph{n} items, both merge sort and quick 
sort have an \emph{average complexity} of $O(n \log n)$, 
which essentially means that the number of operations 
to be performed is proportional to $n \log n$ if 
the number of items to be sorted is $n$, 
with quick sort being usually slightly faster; but 
quick sort has a \emph{worst case complexity} of 
$O(n^{2})$, whereas merge sort has a \emph{worst case 
complexity} of $O(n \log n)$. When the number $n$ of 
items to be sorted grows large, $n^{2}$ becomes 
very significantly larger than $n \log n$. In other 
words, merge sort is deemed to be better because it 
remains efficient in all cases.
\index{algorithmic complexity}
\index{sort!merge sort}
\index{sort!quicksort}

\index{sort!comb sort}
Suppose now that we want to implement another sorting 
algorithm whose performance is alleged to be better. 
For this example, we will use a somewhat exotic sorting 
algorithm known as \emph{comb sort} (aka Dobosiewicz's 
sort), which is described in this page of Wikipedia:
\url{https://en.wikipedia.org/wiki/Comb_sort}. This 
algorithm is said to be \emph{in place}, which means that 
it does not need to copy the items into auxiliary data 
structures, and has generally good performance (often better 
than merge sort), but is not very commonly used in 
practice because its theoretical analysis is very difficult 
(in particular, it seems that it has a good worst-case 
performance, but no one has been able to prove this 
formally so far). In fact, we don't really care about 
the real performance of this sort algorithm; it is 
anyway very unlikely that a pure Perl implementation 
of the comb sort will outperform the built in 
{\tt sort} function implemented in C and probably very 
carefully optimized by its authors. We only want to 
show how a sort subroutine could be implemented.

To work the same way as the internal {\tt sort}, a sort 
function must receive as parameters a comparison function 
or code block and the array to be sorted, and the 
comparison routine should use placeholder parameters (\verb'$^a' 
and  \verb'$^b' in the code below). This is a possible 
basic implementation:
\index{placeholder parameter}

\begin{verbatim}
sub comb_sort (&code, @array) {
    my $max = @array.elems;
    my $gap = $max;
    loop {
        my $swapped = False;
        $gap = Int($gap / 1.3);    # 1.3: optimal shrink factor
        $gap = 1 if $gap < 1;
        my $lmax = $max - $gap - 1;
        for (0..$lmax) -> $i {
            my ($x, $y) = (@array[$i], @array[$i+$gap]);
            (@array[$i], @array[$i+$gap], $swapped) = ($y, $x, True)
                if &code($x, $y) ~~ More;  # or: if &code($x, $y) > 0
        }
        last if $gap == 1 and ! $swapped;
    }
}
\end{verbatim}
\index{sort!comb sort}

This can be tested with the following code:

\begin{verbatim}
my @v;
my $max = 500;
@v[$_] = Int(20000.rand) for (0..$max);

comb_sort {$^a <=> $^b}, @v;
.say for @v[0..10], @v[493..499]; # prints array start and end
# prints (for example):
# (14 22 77 114 119 206 264 293 298 375 391)
# (19672 19733 19736 19873 19916 19947 19967)
\end{verbatim}

The inner loop compares items that are distant from each 
other by \verb'$gap' values, and swaps them if they are 
not in the proper order. At the beginning, \verb'$gap' 
is large and is divided by a shrink factor at each 
iteration of the outer loop. Performance heavily depends
on the value of the shrink factor. At the end, the gap 
is 1 and the comb sort becomes equivalent to a bubble 
sort. The optimal shrink factor lies somewhere between 1.25 
and 1.33; we have used a shrink factor of 1.3, the value 
suggested by the authors of the original publications 
presenting the algorithm.
\index{sort!bubble sort}

\subsection{An iterator version of map}
\index{iter!map}

These {\tt my-map}, {\tt my-grep}, and {\tt comb\_sort} 
functions are pedagogically interesting, but they aren't 
very useful if they do the same thing as their built-in 
counterparts (and are probably slower). However, now 
that we have seen how to build them, we can create our 
own versions doing things differently.

Let's decide we want to create a function that acts like 
{\tt map} in the sense that it does apply a 
transformation on the items of the input list, but does 
that on the items one by one, on demand from a consumer 
process, and pauses when and as long as the consumer process 
does not need anything. This could be described as an 
iterator returning on demand modified elements from the 
source list. You might think that this has not much to 
do with {\tt map}, but it might also be considered as 
a form of {\tt map} with delayed evaluation, which 
processes only the elements of the input lists that are 
necessary for the program, not more than that. 
\index{iterator}
\index{delayed evaluation}

\index{laziness}
\index{lazy!list processing}
The idea 
of processing now only what is strictly required is often call 
{\tt laziness}, and this is a very useful idea. Lazy 
list processing can be very useful not only because it 
avoids processing data that is not needed, and therefore 
can contribute to better resource usage and better 
performance, but also because it makes it possible to consider 
\emph{infinite} lists: so long as you can guarantee that 
you are only going to use a limited number of elements, 
you don't have any problem considering lists that are 
potentially unlimited. Perl~6 provides the concepts and 
tools to do this.
\index{infinite list}

To reflect these considerations, we will call our subroutine 
{\tt iter-map}. Since we might want to also write a 
{\tt iter-grep} subroutine and possibly others, we will 
write separately an iterator and a data transformer.
\index{iterator}

We can use a closure to manufacture an iterator:
\index{closure}

\begin{verbatim}
sub create-iter(@array) {
    my $index = 0;
    return sub { @array[$index++];}
}
my $iterator = create-iter(1..200);
say $iterator() for 1..5; # -> 1, 2, 3, 4, 5
\end{verbatim} 

Now that the iterator returns one value at a time, we 
can write the {\tt iter-map} subroutine:
\index{iter!map}

\begin{verbatim}
sub iter-map (&code-ref, $iter) {
    return &code-ref($iter);
}
my $iterator = create-iter(1..200);
say iter-map { $_ * 2 }, $iterator() for 1..5; # -> 2, 4, 6, 8, 10
\end{verbatim}

Since we have called the {\tt iter-map} function only 5 times, 
it has done the work of multiplying values by 2 only 5 times, 
instead of doing it 200 times, 195 of which for nothing. 
Of course, multiplying a number by 2 isn't an expensive 
operation and the array isn't very large, but this shows 
how laziness can prevent useless computations. We will come 
back to that, since Perl~6 offers native support to lazy 
lists and lazy processing.
\index{laziness}

One additional advantage of using a function such as 
{\tt iter-map} is that it is possible to use 
virtually infinite lists. This works just as before:

\begin{verbatim}
my $iterator = create-iter(1..*);
say iter-map { $_ * 2 }, $iterator() for 1..5;
     # prints 2, 4, 6, 8, 10
\end{verbatim}

\subsection{An iterator version of grep}
\index{iter!grep}

If we try to write a {\tt iter-grep} subroutine on the same 
model:

\begin{verbatim}
my $iterator = create-iter(reverse 1..10);
sub iter-grep (&code_ref, $iter) {
	my $val = $iter();
	return $val if &code_ref($val);
}
# simulating ten calls
say iter-grep { $_ % 2 }, $iterator for 1..10;
\end{verbatim}

it doesn't quite work as desired, because this will print 
alternatively odd values (9, 7, 5, etc.) and undefined 
values (for the even values of the array). Although we 
haven't specified it yet, we would prefer {\tt iter-grep} 
to supply the next value for which the \verb'$code-ref' 
returns true. This implies that {\tt iter-grep} has to 
loop over the values returned by the iterator until it 
receives a proper value.

This might look like this:
\index{iter!grep}

\begin{verbatim}
my $iterator = create-iter(reverse 1..10);
sub iter-grep (&code_ref, $iter) {
	loop {
		my $val = $iter();
		return unless defined $val;  # avoid infinite loop
	    return $val if &code_ref($val);
	}
}
# simulating ten calls
for 1..10 {
	my $val = iter-grep { $_ % 2 }, $iterator;
	say "Input array exhausted!" and last unless defined $val;
	say $val;
}
\end{verbatim}

This now works as expected:

\begin{verbatim}
9
7
5
3
1
Input array exhausted!
\end{verbatim}

However, we still have a problem if the array 
contains some undefined values (or ``empty slots''). This 
would be interpreted as the end of the input array, whereas 
there might be some additional useful values in the array. 
This is sometimes known in computer science as the 
``semi-predicate'' problem. Here, {\tt iter-grep} has no 
way to tell the difference between an empty slot in the array 
and the end of the array. A more robust implementation 
therefore needs a better version of {\tt create-iter}  
returning something different for an undefined array item 
and array exhaustion. For example, the iterator might return 
a false value when done with the array, and a pair with the 
array item as a value otherwise. A pair will be considered 
to be true, even if its value isn't defined. 
\index{semi-predicate problem}
\index{pair}

\begin{verbatim}
sub create-iter(@array) {
    my $index = 0;
    my $max-index = @array.end;
    return sub { 
    	return False if $index >= $max-index; 
        return ("a_pair" => @array[$index++]) 
    }
}
my @array = 1..5;
@array[7] = 15;
@array[9] = 17;
push @array, $_ for 20..22;
.say for '@array is now: ', @array;
my $iterator = create-iter(@array);
sub iter-grep (&code_ref, $iter) {
	loop {
		my $returned-pair = $iter();
		return unless $returned-pair;  # avoid infinite loop
		my $val = $returned-pair.value;
	    return $val if defined $val and &code_ref($val);
	}
}
for 1..10 {
	my $val = iter-grep { $_ % 2 }, $iterator;
	say "Input array exhausted!" and last unless defined $val;
	say $val;
}
\end{verbatim}
\index{iter!grep}

Running this script displays the following:
\begin{verbatim}
@array is now:
[1 2 3 4 5 (Any) (Any) 15 (Any) 17 20 21 22]
1
3
5
15
17
21
Input array exhausted!
\end{verbatim}

This now works fully as desired.

Although {\tt iter-map} did not suffer of the same problem, 
you might want as an exercise to modify {\tt iter-map}
to use our new version of {\tt create-iter}.
\index{iter-map}

The advantage of the iterator functions seen above is that they 
process only the items that are requested by the user code, so 
that they perform only the computations strictly required and 
don't waste CPU cycles and time doing unnecessary work. We have 
gone through these iterating versions of the {\tt map} 
and {\tt grep} functions as a form of case study for 
pedagogical purpose, in order to explain in practical terms 
the idea of laziness. 
\index{laziness}
\index{iterator}

This is what would have been necessary to implement lazy 
iterators in earlier versions of Perl (e.g. Perl~5), but 
much of this is not required with Perl~6 which has built-in 
support for lazy lists and lazy operators, as we will see soon.

\section{The gather and take construct}
\index{gather function}
\index{gather and take construct}
\index{take function}

A useful construct for creating (possibly lazy) lists 
is  \verb'gather { take }'. A \verb'gather' block 
acts more or less like a loop and executes until 
\verb'take' supplies a value. This construct is also 
a form of iterator.

For example, the following code returns a list of 
numbers equal to three times each of the even numbers 
between 1 and 10:

\begin{verbatim}
my @list = gather { 
    for 1..10 {
        take 3 * $_ if $_ %% 2
    } 
};
say @list;                 # -> [6 12 18 24 30]
\end{verbatim}

Here, \verb'gather' loops on the values of the range 
and {\tt take} ``returns'' the wanted values.

If you think about it, the code above seems to 
be doing a form of combination of a {\tt map} and a 
{\tt grep}.
\index{map}
\index{grep}

We can indeed simulate a \verb'map'. For example:

\begin{verbatim}
my @evens = map { $_ * 2 }, 1..5;
\end{verbatim}

could be rewritten with a \verb'gather { take }' 
block :

\begin{verbatim}
my @evens = gather {take $_ * 2 for 1.. 5}; # [2 4 6 8 10]
\end{verbatim}

And we could simulate a {\tt grep} similarly:

\begin{verbatim}
my @evens = gather {take $_ if $_ %% 2 for 1..10}
\end{verbatim}

Since {\tt take} also admits a method syntax, this could 
be rewritten as:

\begin{verbatim}
my @evens = gather {.take if $_ %% 2 for 1..10}
\end{verbatim}


These code examples don't bring any obvious advantage 
over their \verb'map' or {\tt grep} counterparts and 
are not very useful in themselves, but they illustrate 
how a \verb'gather { take }' block can be thought 
of as a generalization of the \verb'map' and 
{\tt grep} functions. And, as already mentioned, 
the first example in this section actually does combine 
the actions of a {\tt map} and a {\tt grep}.

In fact, we can write a new version of {\tt my-map}:
\index{my-map}

\begin{verbatim}
sub my-map (&coderef, @values) {
   return gather {
      take &coderef($_) for @values;
   };
}
say join " ", my-map {$_ * 2}, 1..10;
# prints: 2 4 6 8 10 12 14 16 18 20
\end{verbatim}

Writing a new version of {\tt my-grep} is just 
about as easy and left as an exercise to the reader.
\index{my-grep}

\index{take function}
Calling the {\tt take} function only makes sense 
within the context of a \verb'gather' block, but 
it does not have to be within the block itself 
(or within the lexical scope of the \verb'gather' 
block). Although we don't cover that elsewhere in this book, 
Perl has the notion of \emph{dynamic scope}: contrary 
to lexical scope, dynamic scope encloses not only 
the current block, but also the subroutines called 
from within the current clock. The {\tt take} function 
can work within the dynamic scope of the \verb'gather' 
block, which essentially means that the {\tt take} 
function can be called within a subroutine called from 
the \verb'gather' block. For example:
\index{lexical scope}
\index{dynamic scope}
\index{scope!dynamic}

\begin{verbatim}
my @list = gather {
    compute-val($_) for 1..10; 
}
sub compute-val(Numeric $x) {
    take $x * $x + 2 * $x - 6;
}
say @list[0..5];        # -> (-3 2 9 18 29 42)
\end{verbatim}

As you can see, the {\tt take} function is not called 
within the {\tt gather} block, but it works fine because 
it is within the dynamic scope of the gather block, i.e. 
within the {\tt compute-val} subroutine, which is itself 
called in the {\tt gather} block.

One last example will show how powerful this can be.

Let's consider this problem posted on the Rosetta Code 
site (\url{http://rosettacode.org/wiki/Same_Fringe}): 
Write a routine that will compare the leaves (``fringe'') 
of two binary trees to determine whether they are the 
same list of leaves when visited left-to-right. The 
structure or balance of the trees does not matter; 
only the number, order, and value of the leaves is 
important. 
\index{rosettacode}
\index{binary tree}

The solution in Perl~6 uses a \verb'gather { take }' 
block and holds in just 6~code lines:

\begin{verbatim}
sub fringe ($tree) {
    multi sub fringey (Pair $node) {fringey $_ for $node.kv;}
    multi sub fringey ( Any $leaf) {take $leaf;}
    gather fringey $tree;
}
sub samefringe ($a, $b) { fringe($a) eqv fringe($b) }
\end{verbatim}

Perl~6 is the clear winner in terms of the shortest code to 
solve the problem.

As a comparison, the ADA example is almost 300 lines long, 
the C and Java programs slightly over 100 lines. By the way, 
the shortest solutions besides Perl~6 (Clojure, Picolisp, 
Racket) run in about 20~lines and are all functional 
programming languages, or (for Perl~5 for example) are 
written using functional programming concepts. 
Although the number of code lines is only one of many 
criteria to compare programs and languages, this is 
in my humble opinion a testimony in favor of the functional 
programming paradigm and its inherent expressiveness.
\index{functional programming}


\section{Lazy lists and the sequence operator}
\index{lazy!list}

\subsection{The sequence operator}
\index{sequence operator}
\index{operator!sequence}

Perl provides the \verb'...' sequence operator to build 
lazy lists. For example, this:

\begin{verbatim}
my $lazylist := (0, 1 ... 200);
say $lazylist[42];                 # -> 42
\end{verbatim}

produces a lazy list of successive integers between 0 and 200. 
The Perl~6 compiler may or may not allocate some of the numbers
(depending on the implementation), but it is not required to 
produce the full list immediately. The numbers that have not 
been generated yet may be created and supplied later, if and when 
the program tries to use these values. 

As explained below, if you want to generate consecutive 
integers, you can actually simplify the lazy list definition:

\begin{verbatim}
my $lazylist := (0 ... 200);
\end{verbatim}


\index{laziness}
If you assign a sequence to an array, it will generate 
all the values of the sequence immediately, since 
assignment to an array is eager (non-lazy).  However, 
you can force laziness with the  {\tt lazy} built-in 
when assigning to an array:

\begin{verbatim}
my @lazyarray = lazy 1 ... 200;     # -> [...]
say @lazyarray.elems;               # -> Cannot .elems a lazy list
say @lazyarray[199];                # -> 200
say @lazyarray[200];                # -> (Any)
say @lazyarray.elems;               # -> 200
\end{verbatim}

Here, the \verb'@lazylist' array is originally lazy. 
Evaluating one item past the last element of the array 
forces Perl to actually generate the full array (and the 
array is no longer lazy). After that, no further elements 
can be generated, and {\tt .elems} stays at 200 (unless 
you actually assign values to elements past the 200th 
element).

When given two integers, one for the first and the last items of 
a list, the sequence operator will generate a list of consecutive 
integers between the two supplied integers. If you supply two 
initial items defining implicitly a step, this will generate 
an arithmetic sequence:
\index{arithmetic sequence}

\begin{verbatim}
my $odds = (1, 3 ... 15);          # (1 3 5 7 9 11 13 15)
my $evens = (0, 2 ... 42);         # (0 2 4 6 8 ... 40 42)
\end{verbatim}

You may remember that, in section~\ref{sequence} of the chapter 
on arrays and lists, we said that parentheses are usually not 
necessary for constructing a list, unless needed for 
precedence reasons. The above code is one such example: try 
to run that code without parentheses and observe the content 
of the \verb'$odds' and \verb'evens' variables.

When three numbers in geometric progression are supplied, the 
sequence operator will produce a geometric sequence, as in 
this example producing the powers of two:
\index{geometric sequence}

\begin{verbatim}
say (1, 2, 4 ... 32);              # -> (1 2 4 8 16 32)
\end{verbatim}

The sequence operator may also be used to produce non-integer 
numbers, as shown in this example under the REPL:

\begin{verbatim}
> say (1, 1.1 ... 2);
(1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2)
\end{verbatim}

Contrary to the \verb'..' range operator, the sequence 
operator can also countdown:
\index{range operator}

\begin{verbatim}
say (10 ... 1);                    #  (10 9 8 7 6 5 4 3 2 1)
\end{verbatim}

\subsection{Infinite lists}
\index{infinite list}

One of the great things about lazy lists is that, since 
item evaluation is postponed, they can be infinite without 
consuming infinite resources from the computer:
\index{infinite list}

\begin{verbatim}
my $evens = (0, 2 ... Inf);        # (...)
say $evens[18..21];                # -> (36 38 40 42)
\end{verbatim}

The {\tt Inf} operand is just the so-called ``Texas'' 
or ASCII equivalent of the $\infty$ infinity symbol. 
The above could have been written:
\index{infinity symbol}

\begin{verbatim}
my $evens = (0, 2 ... ∞); 
say $evens[21];                    # -> 42
\end{verbatim} 

The most common way to indicate an infinite lazy list, though, 
is to use the \verb'*' whatever argument:
\index{whatever operator}
\index{operator!whatever}

\begin{verbatim}
my $evens = (0, 2 ... *); 
say $evens[21];                    # -> 42
\end{verbatim} 

\subsection{Using an explicit generator}
\index{sequence operator!generator}

The sequence operator \verb'...' is a very powerful tool 
for generating lazy lists. Given one number, it just 
starts counting up from that number (unless the 
terminal end of the sequence is a lower number, 
in which case it counts down). Given two numbers 
to start a sequence, it will treat it as an arithmetic 
sequence, adding the difference between those first 
two numbers to the last number generated to generate 
the next one. Given three numbers, it checks to see 
if they represent the start of an arithmetic or a 
geometric sequence, and will continue it.
\index{arithmetic sequence}
\index{geometric sequence}

However, many interesting sequences are neither arithmetic 
nor geometric.  They can still be generated with the 
sequence operator provided one term can be deduced from 
the previous one (or ones). For this, you need to explicitly 
provide the code block to generate the next number in 
the sequence. For example, the list of odd integers 
could also be generated with a generator as follows:

\begin{verbatim}
say (1, { $_ + 2 } ... 11);        # -> (1 3 5 7 9 11)
\end{verbatim}

We now have yet another way of defining the factorial 
function:
\index{factorial!with a lazy infinite list}

\begin{verbatim}
my $a;
my @fact = $a = 1, {$_ * $a++} ... *;
say @fact[0..8];          # -> (1 1 2 6 24 120 720 5040 40320)
\end{verbatim}

or, possibly more readable:

\begin{verbatim}
my @fact = 1, { state $a = 1; $_ * $a++} ... *;
say @fact[0..8];          # -> (1 1 2 6 24 120 720 5040 40320)
\end{verbatim}


This approach is much more efficient than those we have 
seen before for repeated use, since it automatically 
caches the previously computed values in the lazy array. 
As you might remember from Section~\ref{memoize} 
(p.~\pageref{memoize}), \emph{caching} is the idea of 
storing a value in memory in order to avoid having to 
recompute it, with the aim of saving time and CPU cycles.
\index{cache}

And we can similarly construct a lazy infinite list of 
Fibonacci numbers:
\index{Fibonacci!numbers}

\begin{verbatim}
my @fibo = 0, 1, -> $a, $b { $a + $b } ... *;
say @fibo[0..10];   # -> (0 1 1 2 3 5 8 13 21 34 55)
\end{verbatim}

This can be rewritten in a more concise (albeit possibly 
less explicit and less clear) way using the \verb'*' 
whatever placeholder parameter:
\index{whatever operator}

\begin{verbatim}
my @fibo = 0, 1, * + * ... *;
say @fibo[^10];      # -> (0 1 1 2 3 5 8 13 21 34)
\end{verbatim}

Just as for factorial, this is more efficient than the 
implementations we've seen previously, because the 
computed values are cached in the lazy array.
\index{cache}

Similarly the sequence of odd integers seen at the 
beginning of this section could be generated in a 
slightly more concise form with the whatever "\verb'*'" 
parameter:
\index{sequence operator}

\begin{verbatim}
say (1, * + 2  ... 11);        # -> (1 3 5 7 9 11)
\end{verbatim}

This syntax with an asterisk is called a 
\emph{whatever closure}, we will come back to 
it below.
\index{whatever closure}

There is, however, a small caveat in using the sequence operator with 
an explicit generator: the end value (the upper bound) has 
to be one of the generated numbers for the list to stop at 
it. Otherwise, it will build an infinite list:

\begin{verbatim}
my $nums = (0, { $_ + 4 } ... 10);
say $nums[0..5];     # -> (0 4 8 12 16 20)
\end{verbatim}

As it can be seen, the generator ``jumps over the end 
point'' (it goes beyond 10), and the list is 
in fact infinite. This is usually not a problem 
in terms of the computer resources, since it is 
a lazy infinite list, but it is probably a bug if 
you expected the list not to run above ten. In this 
specific case, it is very easy to compute an end 
point that will be matched (e.g. 8 or 12), but it may be 
more complicated to find a valid end point. For example, 
it is not obvious to figure out what the largest 
Fibonacci number less than 10,000 might be without 
computing first the series of such numbers until the 
first one beyond 10,000.

In this case, we can define another code block to test 
whether the sequence should stop or continue. The sequence 
will stop if the block returns a true value. For example, 
to compute Fibonacci numbers until 100, we could use this 
under the REPL:

\begin{verbatim}
> my @fibo = 0, 1, -> $a, $b { $a + $b } ... -> $c { $c > 100}
[0 1 1 2 3 5 8 13 21 34 55 89 144]
\end{verbatim}

Okay, it does stop the series of numbers, but not quite exactly 
where we wanted: we really wanted it to stop at the last 
Fibonacci under 100, and we're getting one more. A slight 
change in the syntax will solve this last little problem:

\begin{verbatim}
> my @fibo = 0, 1, -> $a, $b { $a + $b } ...^ -> $c { $c > 100}
[0 1 1 2 3 5 8 13 21 34 55 89]
\end{verbatim}

Switching from \verb'...' to \verb'...^' means the 
resulting list does not include the first element 
for which the termination test returned true.

Similarly, we can limit the \emph{whatever closure} 
syntax seen above as follows:
\index{whatever closure}

\begin{verbatim}
> say 0, 1, * + * ...^ * > 100;
(0 1 1 2 3 5 8 13 21 34 55 89)
\end{verbatim}

\section{Currying and the whatever operator}
\index{curry}

Currying (or partial application) is a basic technique 
of functional programming, especially in pure functional 
programming languages such as Haskell. The ``curry'' name comes 
from the American mathematician Haskell Curry, one of the 
founders (with Alonzo Church) of logical mathematical 
theories, including lambda-calculus and others.
\index{Curry, Haskell}
\index{Church, Alonzo}

To curry a function having several arguments means replacing 
it by a function having only one argument and returning 
another function (often a closure) whose role is to 
process the other arguments.

In some pure functional programming languages, a function 
can only take one argument and return one result. Currying 
is a technique aimed at coping with this apparent limitation. 
Perl does not have such limitation, but currying can still 
be very useful to reduce and simplify the arguments lists 
in subroutine calls, notably in cases of repeated recursive 
calls.


\subsection{Creating a curried subroutine}
\index{curry}

The standard example is an \emph{add} function. Suppose 
we have an add mathematical function, \verb'add(x, y)' 
taking two arguments and returning their sum. 

In Perl, the {\tt add} subroutine is very simple:
\index{add}

\begin{verbatim}
sub add (Numeric $x, Numeric $y) {return $x + $y}
\end{verbatim}

A curried version of it would be another function 
\verb'add_y(x)' returning a function adding $y$ to 
its argument.

This could be done with a closure looking like this:
\index{curry}

\begin{verbatim}
sub make-add (Numeric $added-val) {
    return sub ($param) {$param + $added-val;}    
    # or: return sub {$^a + $added-val;}
}
my &add_2 = make-add 2;
say add_2(3);           # -> 5
say add_2(4.5);         # -> 6.5
\end{verbatim}

The \verb'&add_2' code reference is a curried version 
of our mathematical {\tt add} function. It takes only 
one argument and returns a value equal to the argument 
plus two.

We can of course create other curried subroutines using 
{\tt make-add} with other arguments:

\begin{verbatim}
my &add_3 = make-add 3;
say &add_3(6);           # -> 9
\end{verbatim}

There is not much new here, the \verb'&add_2' and 
\verb'&add_3' are just closures that memorize the 
increment value passed to the {\tt make-add} 
subroutine. This can be useful when some functions 
are called many times (or recursively) with many  
arguments, some of which are always the same: 
currying them makes it possible to simplify the 
subroutine calls.

\subsection{Currying an existing subroutine with the {\tt assuming} method}
\index{curry}
\index{method!assuming}

If a subroutine already exists, there is often no need 
to create a new closure with the help of a ``function 
factory'' (such as {\tt make-add}) as we've done just above. 
It is possible to curry the existing function, using 
the {\tt assuming} method on it:
\index{assuming method}

\begin{verbatim}
sub add (Numeric $x, Numeric $y) {return $x + $y}   
my &add_2 = &add.assuming(2);                       
add_2(5);              # -> 7                                     
\end{verbatim}

The {\tt assuming} method returns a callable object 
that implements the same behavior as the original 
subroutine, but has the values passed to {\tt assuming}
already bound to the corresponding parameters.

It is also possible to curry built-in functions. For example, 
the {\tt substr} built-in takes normally three arguments:
the string on which to operate, the start position and the 
length of the substring to be extracted. You might need 
to make a number of extractions on the same very long 
string. You can create a curried version of {\tt substr} 
always working on the same string:
\index{substr function}

\begin{verbatim}
my $str = "Cogito, ergo sum";                     
my &string-start-chars = &substr.assuming($str, 0);
say &string-start-chars($_) for 6, 13, 16; 
\end{verbatim}

This will print:

\begin{verbatim}
Cogito
Cogito, ergo
Cogito, ergo sum
\end{verbatim}

Note that we have ``assumed'' two parameters here, so 
that the curried subroutine ``remembers'' the first 
two arguments and only the third argument needs be 
passed to \verb'&string-start-chars'.

You can even curry Perl~6 operators (or your own) if 
you wish:
\index{assuming method}

\begin{verbatim}
my &add_2 = &infix:<+>.assuming(2);
\end{verbatim}

\subsection{Currying with the whatever star parameter}
\index{curry}
\index{whatever term}
\label{whatever star parameter}

A more flexible way to curry a subroutine or an expression 
is to use the \emph{whatever star} ``*'' argument:

\begin{verbatim}
my &third = * / 3; 
say third(126);          # -> 42
\end{verbatim}

The \emph{whatever star} ``*'' is a placeholder for 
an argument, so that the expression returns in fact 
a closure.

It can be used in a way somewhat similar to the \verb'$_' 
topical variable (except that it does not have to exist 
when the declaration is made):

\begin{verbatim}
> say map 'foo' x * , (1, 3, 2);
(foo foofoofoo foofoo)
\end{verbatim}

It is also possible to use multiple {\tt whatever} terms 
in the same expression. For example, the {\tt add} 
subroutine could be rewritten as a {\tt whatever} 
expression with two parameters:

\begin{verbatim}
my $add = * + *;
say $add(4, 5);          # -> 9
\end{verbatim}

or:

\begin{verbatim}
my &add = * + *;
say add(4, 5);           # -> 9
\end{verbatim}

You might even do the same with the multiplication operator:

\begin{verbatim}
my $mult = * * *;
say $mult(6, 7);         # -> 42
\end{verbatim}

and the compiler won't get confused and will figure out 
correctly that the first and third asterisks are 
\verb'whatever' terms and that the second asterisk is 
the multiplication operator, in other words that this is 
more or less equivalent to:

\begin{verbatim}
my $mult = { $^a * $^b };
say $mult(6, 7);         # -> 42
\end{verbatim}

or to:

\begin{verbatim}
my $mult = -> $a, $b { $a * $b }
say $mult(6, 7);         # -> 42  
\end{verbatim}

To tell the truth, the compiler doesn't get confused, 
but the user might, unless she or he has been previously 
exposed with some functional programming languages using 
commonly this type of syntactic construct. 

These ideas are powerful, but you are advised to pay 
attention not to fall into the trap of code obfuscation.

That being said, the functional programming paradigm 
is extremely expressive and can make your code much 
shorter. And, overall, shorter code, provided it remains 
clear and easy to understand, is very likely to have 
fewer bugs than longer code.

\section{Debugging}
\label{test_module}
\index{testing!automated tests}

This time, we will not really talk about debugging proper, 
but about a quite closely related activity, testing.

Testing code is an integral part of software development. In 
Perl~6, the standard {\tt Test} module (shipped and installed 
together with Rakudo) provides a testing framework which enables 
automated, repeatable verification of code behavior.
\index{test module}
\index{testing!module}

The testing functions emit output conforming to the \emph{Test 
Anything Protocol} or TAP (\url{http://testanything.org/}), a 
standardized testing format which has implementations in Perl, 
C, C++, C\#, Ada, Lisp, Erlang, Python, Ruby, Lua, PHP, Java, 
Go, JavaScript, and other languages.

A typical test file looks something like this:

\begin{verbatim}
use v6;
use Test;      # a Standard module included with Rakudo
use lib 'lib';

# ...

plan $num-tests;

# .... tests

done-testing;  # optional with 'plan'
\end{verbatim}

We ensure that we're using Perl~6, via the use of the v6 pragma, 
then we load the Test module and specify where our 
libraries are. We then specify how many tests we plan 
to run (such that the testing framework can tell us 
if more or fewer tests were run than we expected) 
and when finished with the tests, we use {\tt done-testing} 
to tell the framework we are done.

We have already seen a short example of the use of the Test 
module in section~\ref{sol_fact_operator} (solution 
to the exercise of section~\ref{operator_construction}).

The Test module exports various functions that check the return 
value of a given expression, and produce standardized test 
output accordingly.

In practice, the expression will often be a call to a function 
or method that you want to unit-test. You may want to check:

\begin{itemize}
\item Truthfulness: 
\begin{verbatim}
ok($value, $description?); 
nok($condition, $description?)
\end{verbatim}
\index{ok function (testing)}
\index{nok function (testing)}
\index{test module!ok function}
\index{test module!nok function}

The {\tt ok} function marks a test as passed if the given 
\verb'$value' evaluates to True in a boolean context. The 
{\tt nok} function marks a test as passed if the given value 
evaluates to False. Both functions accept an optional 
\verb'$description' of the test. For example:

\begin{verbatim}
ok  $response.success, 'HTTP response was successful';
nok $query.error,      'Query completed without error';
\end{verbatim}

\item String comparison:
\begin{verbatim}
is($value, $expected, $description?)
\end{verbatim}
\index{is function (testing)}
\index{test module!is function}

The {\tt is} function marks a test as passed if \verb'$value' 
and \verb'$expected' compare positively with the eq operator. 
The function accepts an optional description of the test.
\index{string equality}

\item Approximate numeric comparison:

\begin{verbatim}
is-approx($value, $expected, $description?)
\end{verbatim}
\index{is-approx function (testing)}
\index{test module!is-approx function}

{\tt is-approx} marks a test as passed if the \verb'$value' and 
\verb'$expected' numerical values are approximately equal 
to each other. The subroutine can be called in numerous ways 
that let you test using relative or absolute tolerance 
of different values. (If no tolerance is set, it will default 
to an absolute tolerance of $10^{-5}$.)
\index{approximate numeric equality}

\item Regex:

\begin{verbatim}
like($value, $expected-regex, $description?)
unlike($value, $expected-regex, $description?)
\end{verbatim}
\index{like function (testing)}
\index{unlike function (testing)}
\index{test module!like function}
\index{test module!unlike function}

The {\tt like} function marks a test as passed if the 
\verb'$value' matches the \verb'$expected-regex'. Since 
we are speaking about regexes, ``matches'', in the 
previous sentence, really means ``smart-matches''. The 
{\tt unlike} function marks a test as passed if the 
\verb'$value' does not match the \verb'$expected-regex'.

For example:
\begin{verbatim}
like 'foo', /fo/, 'foo looks like fo';
unlike 'foo', /bar/, 'foo does not look like bar';
\end{verbatim}

\item And many other functions which you can study in the 
following documentation: \url{https://docs.perl6.org/language/testing.html}.

\end{itemize}

In principle you could use {\tt ok} for every kind of 
comparison test, by including the comparison in the 
expression passed as a value:
\index{factorial}

\begin{verbatim}
ok factorial(4) == 24, 'Factorial - small integer';
\end{verbatim}

However, it is better (where possible) to use one of the 
specialized comparison test functions, because they can 
print more helpful diagnostics output in case the comparison 
fails.

If a test fails although it appears to be successful, and 
you don't understand why it fails, you may want to use the 
\verb'diag' function to get additional feed back. For example,
assuming you have the following test:

\begin{verbatim}
ok $foo, 'simple test';
\end{verbatim} 

failing and that you don't have enough feed-back to 
understand why, you may try:
\index{diag}

\begin{verbatim}
diag "extensive feedback" unless
    ok $foo, 'simple test';
\end{verbatim}

This might give you the additional information you need.

Suppose we want to test a subroutine to determine whether a 
given string is a palindrome (as discussed in several chapters 
in this book, see for example exercise~/ref{palindrome} and 
subsection~\ref{palindrome_2}). This could be something 
like this:
\index{palindrome}

\begin{verbatim}
# file is-palindrome.p6
use v6;

sub is-palindrome($s) { $s eq $s.flip }

multi sub MAIN( $input ) {
    if is-palindrome( $input ) {
        say "'$input' is palindrome.";
    }
    else {
        say "'$input' is not palindrome.";
    }
}

multi sub MAIN(:$test!) {
    use Test;
    plan 4;
    ok is-palindrome(''), 'empty string';
    ok is-palindrome('aba'), 'odd-sized example';
    ok is-palindrome('abba'), 'even-sized example';
    nok is-palindrome('blabba'), 'counter example';
}
\end{verbatim}

Usually, tests are stored in different files placed in a ``t'' 
sub-directory. Here, for this short test, everything is in the 
same file, but two multi {\tt MAIN} subroutines are supplied 
to either test if a passed parameter is a palindrome, or to 
run the test plan. See section~\ref{MAIN} (p.~\pageref{MAIN} and 
subsection~\ref{MAIN_sub} (p.~\pageref{MAIN_sub}) if you don't 
remember about the {\tt MAIN} subroutine.
\index{MAIN}
\index{multi subroutines}

You can run these tests as follows:

\begin{verbatim}
$ perl6 is-palindrome.p6 abba
'abba' is palindrome.
$ perl6 is-palindrome.p6 abbaa
'abbaa' is not palindrome.
$
$ perl6 is-palindrome.p6 --test
1..4
ok 1 - empty string
ok 2 - odd-sized example
ok 3 - even-sized example
ok 4 - counter example
\end{verbatim}

Try this example, play with it, change some lines, add 
new tests, and see what happens.

Writing such unit tests may appear to be tedious work. 
The truth, though, is that it is manual testing which is 
somewhat tedious and, it you try, you'll find that 
writing and using such test scenarios makes the testing 
work much less cumbersome. You usually write the tests 
once, and run them very often. And you will be surprised 
how many bugs you will find even if you are sure your 
code is correct! Also, once you've written 
a test suite for something, you might still be using it 
years later, for example for non-regression testing after 
a software change. This can be not only a time saver, but 
also a guarantee that you're supplying good quality software.
\index{non-regression test}

Many organizations actually write their tests even before 
writing the programs. This process is called 
\emph{test-driven development} and there are many areas where 
it is quite successful. In fact, the Rakudo/Perl~6 compiler 
had a very large test suite (more than 40,000 tests) long 
before the compiler was ready. In a way, the test suite 
even became the true specification of the project, so that 
you could use the same test suite for verifying another 
implementation of Perl~6.
\index{test-driven development}

An additional advantage of 
such an approach is that measuring the ratio of tests that 
pass may often be a better metric of software completion than  
usual ``wet finger in the wind'' estimates, such as, say, a ratio of 
the number of code lines written versus the estimate of 
the final number of code lines.
\index{software metric}

\section{Glossary}

\begin{description}

\item[First-class object:] an object that can be passed around 
as an argument to or as a return value from a subroutine. In 
Perl, subroutine are first-class objects or first-class citizens. 
\index{first-class object}
\index{first-class citizen}

\item[callback function:] a function or subroutine that is 
passed as an argument to another function.
\index{callback function}

\item[higher-order function:] a function or subroutine that takes 
another subroutine (or a simple code block) as an argument. The 
{\tt map}, {\tt grep}, {\tt reduce}, and {\tt sort} built-in 
functions are examples of such higher-order functions.
\index{higher-order function}
\index{function!higher-order}

\item[anonymous subroutine:] a subroutine that has no name. Also 
commonly called a \emph{lambda}. Although they are not exactly 
the same thing, pointy blocks can also be assimilated to 
anonymous subroutines.
\index{anonymous subroutine}
\index{lambda}

\item[closure:] a function that can access to variables that 
are lexically available where the function is defined, even 
if those variables are no longer in scope where the function 
is called.
\index{closure}

\item[pipe-line programming:] a programming model in which 
pieces of data (usually lists) are undergoing successive 
transformations as in a pipe-line or an assembly line.
\index{pipe-line programming}

\item[reduction:] a process through which a list of values is 
reduced to a single value. For example, a list of numbers 
can be reduced to an average, a maximum value or a median. 
Some languages call this process \emph{folding}.
\index{reduction}

\item[metaoperator:] an operator that acts on another operator 
to provide new functionality.
\index{metaoperator}

\item[algorithmic complexity:] a rough measure of the number 
of computing operations (and time) needed to perform some 
computing on relatively large data sets, and, more precisely, 
a measure of how an algorithm scales when the data set grows.
\index{algorithmic complexity}

\item[laziness:] a process of delayed evaluation whereby, for 
example, one populates a list or processes the items of a list only 
on demand, when required, to avoid unnecessary processing.
\index{laziness}

\item[iterator:] A piece of code that returns values on demand 
and keeps track of where it has arrived, so as to be able 
to know what the next value should be.
\index{iterator}

\item[cache:] To cache a value is to store it in memory (in a 
variable, an array, a hash, etc.) in order to avoid the need to 
compute it again, thereby hopefully saving some computation time.
\index{cache}

\item[currying:] currying a function taking several arguments is 
to create another function taking fewer arguments (where the missing 
arguments are stored within the curried function).
\index{curry}

\item[test-driven development:] a development methodology 
where the tests are written from the specifications before 
the actual program, so that it becomes easier to check that 
the program complies with the specification.
\index{test-driven development}

\end{description}
